{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d980af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.pipeline.merge_parquet' from 'D:\\\\amazon-reviews\\\\src\\\\pipeline\\\\merge_parquet.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test file load_data\n",
    "\n",
    "from importlib import reload\n",
    "import os\n",
    "os.chdir(\"D:/amazon-reviews\") # Run always on the root to avoid problems\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from src.load_data import load_info, multiple_files #I mport funtion from file\n",
    "from src.text.clean_text import clean\n",
    "import src.text.lang_detection as lt\n",
    "reload(lt)\n",
    "import src.pipeline.ingestion as ingest\n",
    "reload(ingest)\n",
    "import src.pipeline.merge_parquet as mp\n",
    "reload(mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b01991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Industrial_and_Scientific.json.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000020D14909190>>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\amazon-reviews\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 812, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1535, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 1758333 rows and 12 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>01 23, 2013</td>\n",
       "      <td>A3FANY5GOT5X0W</td>\n",
       "      <td>0176496920</td>\n",
       "      <td>Kelly Keyser</td>\n",
       "      <td>Arrived on time, in mint condition, great!  I ...</td>\n",
       "      <td>Just as described!</td>\n",
       "      <td>1358899200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>11 5, 2012</td>\n",
       "      <td>AT6HRPPYOPHMB</td>\n",
       "      <td>0176496920</td>\n",
       "      <td>Michael C</td>\n",
       "      <td>This device was hard to find for my daughter's...</td>\n",
       "      <td>Great device</td>\n",
       "      <td>1352073600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>10 17, 2012</td>\n",
       "      <td>A4IX7B38LIN1E</td>\n",
       "      <td>0176496920</td>\n",
       "      <td>BH</td>\n",
       "      <td>Just a clicker nothing special. Was hoping it ...</td>\n",
       "      <td>Pretty Good</td>\n",
       "      <td>1350432000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 29, 2017</td>\n",
       "      <td>A12Q4LR8N17AOZ</td>\n",
       "      <td>0176496920</td>\n",
       "      <td>Waterfall3500</td>\n",
       "      <td>Great response card. Slow shipping but it work...</td>\n",
       "      <td>Thank you for the great product. Works. A++ Us...</td>\n",
       "      <td>1490745600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>03 21, 2017</td>\n",
       "      <td>A1GJXZZPOZ3OD9</td>\n",
       "      <td>0176496920</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>It only lasted for 3 days before it stopped wo...</td>\n",
       "      <td>One Star</td>\n",
       "      <td>1490054400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True  01 23, 2013  A3FANY5GOT5X0W  0176496920   \n",
       "1        5      True   11 5, 2012   AT6HRPPYOPHMB  0176496920   \n",
       "2        4      True  10 17, 2012   A4IX7B38LIN1E  0176496920   \n",
       "3        5      True  03 29, 2017  A12Q4LR8N17AOZ  0176496920   \n",
       "4        1      True  03 21, 2017  A1GJXZZPOZ3OD9  0176496920   \n",
       "\n",
       "      reviewerName                                         reviewText  \\\n",
       "0     Kelly Keyser  Arrived on time, in mint condition, great!  I ...   \n",
       "1        Michael C  This device was hard to find for my daughter's...   \n",
       "2               BH  Just a clicker nothing special. Was hoping it ...   \n",
       "3    Waterfall3500  Great response card. Slow shipping but it work...   \n",
       "4  Amazon Customer  It only lasted for 3 days before it stopped wo...   \n",
       "\n",
       "                                             summary  unixReviewTime vote  \\\n",
       "0                                 Just as described!      1358899200  NaN   \n",
       "1                                       Great device      1352073600  NaN   \n",
       "2                                        Pretty Good      1350432000  NaN   \n",
       "3  Thank you for the great product. Works. A++ Us...      1490745600  NaN   \n",
       "4                                           One Star      1490054400  NaN   \n",
       "\n",
       "  style image  \n",
       "0   NaN   NaN  \n",
       "1   NaN   NaN  \n",
       "2   NaN   NaN  \n",
       "3   NaN   NaN  \n",
       "4   NaN   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1\n",
    "\n",
    "df = load_info(\"data/raw/Industrial_and_Scientific.json.gz\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33874824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('data/raw/Electronics.json.gz')]\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "\n",
    "files = multiple_files()\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e643077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files found in data/raw/\n",
      "Electronics.json.gz\n",
      "Industrial_and_Scientific.json.gz\n"
     ]
    }
   ],
   "source": [
    "# Test 3 - Try the first step of the pipeline ingestion READ THE FILES using funtions created in load_data\n",
    "\n",
    "raw_files = ingest.list_raw_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ada6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk test in file: Electronics.json.gz\n",
      "1000 rows loaded for first chunk\n",
      "   overall  verified   reviewTime      reviewerID      asin  \\\n",
      "0        5      True  07 17, 2002  A1N070NS9CJQ2I  60009810   \n",
      "1        5     False   07 6, 2002  A3P0KRKOBQK1KN  60009810   \n",
      "2        5     False   07 3, 2002  A192HO2ICJ75VU  60009810   \n",
      "3        4     False  06 30, 2002  A2T278FKFL3BLT  60009810   \n",
      "4        5     False  06 28, 2002  A2ZUXVTW8RXBXW  60009810   \n",
      "\n",
      "                       style reviewerName  \\\n",
      "0  {'Format:': ' Hardcover'}   Teri Adams   \n",
      "1  {'Format:': ' Hardcover'}     Willa C.   \n",
      "2  {'Format:': ' Hardcover'}          Kit   \n",
      "3  {'Format:': ' Hardcover'}       Andres   \n",
      "4  {'Format:': ' Hardcover'}         John   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0  This was the first time I read Garcia-Aguilera...   \n",
      "1  As with all of Ms. Garcia-Aguilera's books, I ...   \n",
      "2  I've not read any of Ms Aguilera's works befor...   \n",
      "3  This romance novel is right up there with the ...   \n",
      "4  Carolina Garcia Aguilera has done it again.  S...   \n",
      "\n",
      "                          summary  unixReviewTime  vote image  \n",
      "0                   Hit The Spot!      1026864000   NaN   NaN  \n",
      "1  one hot summer is HOT HOT HOT!      1025913600   NaN   NaN  \n",
      "2                  One Hot Summer      1025654400   2.0   NaN  \n",
      "3               I love this book!      1025395200   3.0   NaN  \n",
      "4                    One Hot Book      1025222400   NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Test 4 -  try to read one chunk\n",
    "\n",
    "if len(raw_files) > 0: # Verify raw_files is not empty \n",
    "    file_one = raw_files[0]\n",
    "    print(f\"Chunk test in file: {file_one.name}\")\n",
    "\n",
    "    for chunk in pd.read_json(file_one, lines=True, chunksize=1000):\n",
    "        print(f\"{len(chunk)} rows loaded for first chunk\")\n",
    "        print(chunk.head()) # Show first rows\n",
    "        break  # Just to test with chunk #1\n",
    "else:\n",
    "    print(\"No files found in data/raw/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b1ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: This was the first time I read Garcia-Aguilera.  I came upon the name of this book on Live with Regis and Kelly. This book was exactly what I was looking for ... it hit the spot.  I really enjoyed this book because it was well written. Once I started this book it kept me coming back for more. It had culture, family, friendship and romance. I was looking for a little more romance when I picked this book but in the end it turned out to be just right.  I love the main chartachter Margarita (aka Daisy). I've never been to Miami but the way Daisy told the story I certainly felt I'd been there.\n",
      "Also after going through all of Daisy's perils ... I closed the book with a feeling I had grown emotionally as well.    \n",
      "After: this was the first time i read garcia-aguilera i came upon the name of this book on live with regis and kelly this book was exactly what i was looking for it hit the spot i really enjoyed this book because it was well written once i started this book it kept me coming back for more it had culture family friendship and romance i was looking for a little more romance when i picked this book but in the end it turned out to be just right i love the main chartachter margarita (aka daisy) i've never been to miami but the way daisy told the story i certainly felt i'd been there also after going through all of daisy's perils i closed the book with a feeling i had grown emotionally as well\n",
      "\n",
      "\n",
      "Before: As with all of Ms. Garcia-Aguilera's books, I think this is a MUST READ, impossible to put down. Successful deviation from past Lupe Solano series-captures the very essence of the excitement, local color and diverse fabric of MIAMI. Sensual and culturally enlightened!    \n",
      "After: as with all of ms garcia-aguilera's books i think this is a must read impossible to put down successful deviation from past lupe solano series-captures the very essence of the excitement local color and diverse fabric of miami sensual and culturally enlightened\n",
      "\n",
      "\n",
      "Before: I've not read any of Ms Aguilera's works before, but after having just finished One Hot Summer I'm going to check out the Lupe Solano series I've heard so much about.  One Hot Summer is sooo steamy! Made me want to move to Miami!  Couldn't put the book down.    \n",
      "After: i've not read any of ms aguilera's works before but after having just finished one hot summer i'm going to check out the lupe solano series i've heard so much about one hot summer is sooo steamy made me want to move to miami couldn't put the book down\n",
      "\n",
      "\n",
      "Before: This romance novel is right up there with the rest of her amazing mystery novels.  Being a guy, I was a little hesitant about reading a romance novel but I just had to give this book a shot because I have been such a huge fan of Garcia-Aguilera's books.  And to be honest, I absolutely loved this book.  I love the way she presents funky Miami and its crazy Cubans in not just this book but all her books.  Garcia-Aguilera did a superb job with this book, and I can't wait till her next book.  You gotta read this book!!!!    \n",
      "After: this romance novel is right up there with the rest of her amazing mystery novels being a guy i was a little hesitant about reading a romance novel but i just had to give this book a shot because i have been such a huge fan of garcia-aguilera's books and to be honest i absolutely loved this book i love the way she presents funky miami and its crazy cubans in not just this book but all her books garcia-aguilera did a superb job with this book and i can't wait till her next book you gotta read this book\n",
      "\n",
      "\n",
      "Before: Carolina Garcia Aguilera has done it again.  She's written another highly enjoyable book and infused it with the right amount of Cuban-American tidbits.  My family and I cannot put her books down once we start and this one was not a let down.    \n",
      "After: carolina garcia aguilera has done it again she's written another highly enjoyable book and infused it with the right amount of cuban-american tidbits my family and i cannot put her books down once we start and this one was not a let down\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try 4 - Apply the cleaning module to the reviewText column\n",
    "\n",
    "# Take the column review text from chunk\n",
    "rText = chunk['reviewText']\n",
    "\n",
    "# Apply cleaning\n",
    "\n",
    "rText_cleaned = rText.apply(clean)\n",
    "\n",
    "for org, cleaned in zip(rText.head(5), rText_cleaned.head(5)):\n",
    "\n",
    "    print(f\"Before: {org}    \")\n",
    "    print (f\"After: {cleaned}\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9269027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 1000\n",
      "\n",
      "English reviews: 921\n"
     ]
    }
   ],
   "source": [
    "# Test 5 - Try the langdetect module on the chunk\n",
    "\n",
    "english_rows = rText_cleaned.apply(lt.is_english)\n",
    "\n",
    "cont = 0 \n",
    "\n",
    "for a in english_rows:\n",
    "    if a == True:\n",
    "        cont+=1\n",
    "\n",
    "print(f\"Original size: {rText_cleaned.size}\\n\")\n",
    "print(f\"English reviews: {cont}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e2114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 files found. Ingestion started.\n",
      "\n",
      "Processing file Electronics.json.gz\n",
      "\n",
      "5000 rows loaded\n",
      "\n",
      "Original rows: 5000\n",
      "English reviews: 4640\n",
      "Reviews not considered: 360\n",
      "\n",
      "\n",
      "Processing file Industrial_and_Scientific.json.gz\n",
      "\n",
      "5000 rows loaded\n",
      "\n",
      "Original rows: 5000\n",
      "English reviews: 4259\n",
      "Reviews not considered: 741\n",
      "\n",
      "\n",
      "Processing file Musical_Instruments.json.gz\n",
      "\n",
      "5000 rows loaded\n",
      "\n",
      "Original rows: 5000\n",
      "English reviews: 4556\n",
      "Reviews not considered: 444\n",
      "\n",
      "\n",
      "Processing file Video_Games.json.gz\n",
      "\n",
      "5000 rows loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 6 - Try the chunk loading with the pipeline module check\n",
    "\n",
    "ingest.processing_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea0af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing started...\n",
      "\n",
      "Processing file Electronics.json.gz\n",
      "\n",
      "Electronics.json already processed. Moving to the next file.\n",
      "\n",
      "Processing file Home_and_Kitchen.json.gz\n",
      "\n",
      "\n",
      "Writing in data\\processed\\Home_and_Kitchen.json.temp.parquet started.\n",
      "\n",
      "Processing file Industrial_and_Scientific.json.gz\n",
      "\n",
      "Industrial_and_Scientific.json already processed. Moving to the next file.\n",
      "\n",
      "Processing file Musical_Instruments.json.gz\n",
      "\n",
      "Musical_Instruments.json already processed. Moving to the next file.\n",
      "\n",
      "Processing file Video_Games.json.gz\n",
      "\n",
      "Video_Games.json already processed. Moving to the next file.\n",
      "\n",
      "File data\\processed\\Video_Games.json.parquet generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Try 7 - Try the actual pipeline with parquet file saving\n",
    "ingest.save_to_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5381622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 processed entries from TXT file.\n",
      "dataset_embedding.parquet already exists, checking if there is new files to append...\n",
      "\n",
      "No files to add.\n"
     ]
    }
   ],
   "source": [
    "# Try 8 - Test the merging function\n",
    "\n",
    "mp.merge_par()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6ec00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
